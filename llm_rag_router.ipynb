{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#multiagent using rag and llm in langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langgraph.graph import START,StateGraph,END\n",
    "from typing import Annotated\n",
    "from typing import TypedDict,Sequence\n",
    "import operator\n",
    "from IPython.display import display,Image\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langgraph.prebuilt import ToolNode,tools_condition\n",
    "from langchain.tools import tool\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.messages import BaseMessage\n",
    "from pydantic import BaseModel,Field\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HF_TOKEN\"]=os.getenv(\"HF_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\OneDrive\\Desktop\\langgraph\\myvenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "embedding=HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=ChatGroq(model=\"gemma2-9b-it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"**Gen AI**, short for **Generative Artificial Intelligence**, is a type of artificial intelligence that focuses on creating new content. \\n\\nThink of it like this:\\n\\n* **Traditional AI:**  Good at analyzing existing data, recognizing patterns, and making predictions. \\n* **Gen AI:** Takes that understanding of patterns and uses it to build something entirely new.\\n\\n**What can Gen AI create?**\\n\\n* **Text:**  Stories, poems, articles, code, scripts, emails, letters\\n* **Images:** Photos, artwork, illustrations, 3D models\\n* **Audio:** Music, sound effects, voiceovers\\n* **Video:** Animations, short films\\n* **Other:**  Synthetic data, game levels, chemical compounds\\n\\n**How does it work?**\\n\\nGen AI models are typically trained on massive datasets of existing content. They learn the underlying rules and structures of that data, then use that knowledge to generate new content that follows similar patterns. \\n\\n* **Deep Learning:**  A key technique used in Gen AI is deep learning, which involves artificial neural networks with many layers. These networks can learn complex relationships in data and generate highly realistic outputs.\\n\\n**Examples of Gen AI tools:**\\n\\n* **ChatGPT:**  Generates human-like text in response to prompts.\\n* **DALL-E 2:** Creates images from textual descriptions.\\n* **Midjourney:**  Generates artistic images from text prompts.\\n* **Jukebox:**  Composes music in various styles.\\n\\n**Applications of Gen AI:**\\n\\n* **Content Creation:** Writing marketing copy, generating ideas for stories, creating artwork.\\n* **Education:**  Developing personalized learning experiences, generating practice questions.\\n* **Research:**  Creating synthetic data for testing and analysis.\\n* **Entertainment:**  Generating game content, creating realistic special effects.\\n\\n**Ethical considerations:**\\n\\n* **Bias:**  Gen AI models can inherit biases present in the training data, leading to unfair or discriminatory outputs.\\n* **Misinformation:**  Gen AI can be used to create convincing fake news and other forms of misinformation.\\n* **Copyright:**  The ownership and copyright of content generated by Gen AI is a complex legal issue.\\n\\n\\nGen AI is a rapidly evolving field with the potential to revolutionize many industries. However, it's important to be aware of the ethical considerations and potential risks associated with this technology.\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 496, 'prompt_tokens': 13, 'total_tokens': 509, 'completion_time': 0.901818182, 'prompt_time': 7.778e-05, 'queue_time': 0.01998018, 'total_time': 0.901895962}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-9c30a666-e884-46c9-a31e-699b3dd81b37-0', usage_metadata={'input_tokens': 13, 'output_tokens': 496, 'total_tokens': 509})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"what is gen ai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader=PyPDFLoader(file_path=\"C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langgraph\\\\temp.pdf\")\n",
    "docs=loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents=RecursiveCharacterTextSplitter(chunk_size=400,chunk_overlap=40).split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langgraph\\\\temp.pdf', 'page': 0}, page_content='From Wikipedia, the free encyclopedia \\nAn illustration of main components of the \\ntransformer model from the paper \\n\"Attention Is All You Need\"[1] is a 2017 landmark[2][3] research paper in machine learning authored by \\neight scientists working at Google. The paper introduced a new deep learning architecture known as'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langgraph\\\\temp.pdf', 'page': 0}, page_content='the transformer, based on the attention mechanism proposed in 2014 by Bahdanau et al.[4] It is \\nconsidered a foundational[5] paper in modern artificial intelligence, as the transformer approach has \\nbecome the main architecture of large language models like those based on GPT.[6][7] At the time, the'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langgraph\\\\temp.pdf', 'page': 0}, page_content='focus of the research was on improving Seq2seq techniques for machine translation, but the authors \\ngo further in the paper, foreseeing the technique\\'s potential for other tasks like question \\nanswering and what is now known as multimodal Generative AI.[1] \\nThe paper\\'s title is a reference to the song \"All You Need Is Love\" by the Beatles.[8] The name'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langgraph\\\\temp.pdf', 'page': 0}, page_content='\"Transformer\" was picked because Uszkoreit liked the sound of that word.[9] \\nAn early design document was titled \"Transformers: Iterative Self-Attention and Processing for \\nVarious Tasks\", and included an illustration of six characters from the Transformers animated show. \\nThe team was named Team Transformer.[8]'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langgraph\\\\temp.pdf', 'page': 0}, page_content='Some early examples that the team tried their Transformer architecture on included English-to-\\nGerman translation, generating Wikipedia articles on \"The Transformer\", and parsing. These \\nconvinced the team that the Transformer is a general purpose language model, and not just good for \\ntranslation.[9] \\nAs of 2024, the paper has been cited more than 100,000 times.[10]'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langgraph\\\\temp.pdf', 'page': 0}, page_content='For their 100M-parameter Transformer model, they suggested learning rate should be linearly scaled \\nup from 0 to maximal value for the first part of the training (i.e. 2% of the total number of training \\nsteps), and to use dropout, to stabilize training. \\nAuthors \\n[edit] \\nThe authors of the paper are: Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langgraph\\\\temp.pdf', 'page': 0}, page_content='Jones, Aidan Gomez, Lukasz Kaiser, and Illia Polosukhin. All eight authors were \"equal contributors\" \\nto the paper; the listed order was randomized. The Wired article highlights the group\\'s diversity:[8]'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langgraph\\\\temp.pdf', 'page': 1}, page_content='Six of the eight authors were born outside the United States; the other two are children of two \\ngreen-card-carrying Germans who were temporarily in California and a first-generation American \\nwhose family had fled persecution, respectively. \\nBy 2023, all eight authors had left Google and founded their own AI start-ups (except Łukasz Kaiser, \\nwho joined OpenAI).[8][10] \\nHistorical context \\n[edit]'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langgraph\\\\temp.pdf', 'page': 1}, page_content='Historical context \\n[edit] \\nMain articles: Transformer (deep learning architecture) § History, and Seq2seq § History \\nSee also: Timeline of machine learning \\nPredecessors \\n[edit] \\nFor many years, sequence modelling and generation was done by using plain recurrent neural \\nnetworks (RNNs). A well-cited early example was the Elman network (1990). In theory, the'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langgraph\\\\temp.pdf', 'page': 1}, page_content=\"information from one token can propagate arbitrarily far down the sequence, but in practice \\nthe vanishing-gradient problem leaves the model's state at the end of a long sentence without \\nprecise, extractable information about preceding tokens. \\nA key breakthrough was LSTM (1995),[note 1] a RNN which used various innovations to overcome the\"),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langgraph\\\\temp.pdf', 'page': 1}, page_content='vanishing gradient problem, allowing efficient learning of long-sequence modelling. One key \\ninnovation was the use of an attention mechanism which used neurons that multiply the outputs of \\nother neurons, so-called multiplicative units.[11] Neural networks using multiplicative units were later \\ncalled sigma-pi networks[12] or higher-order networks.[13] LSTM became the standard architecture for'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langgraph\\\\temp.pdf', 'page': 1}, page_content='long sequence modelling until the 2017 publication of Transformers. However, LSTM still used \\nsequential processing, like most other RNNs.[note 2] Specifically, RNNs operate one token at a time \\nfrom first to last; they cannot operate in parallel over all tokens in a sequence. \\nModern Transformers overcome this problem, but unlike RNNs, they require computation time that'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langgraph\\\\temp.pdf', 'page': 1}, page_content='is quadratic in the size of the context window. The linearly scaling fast weight controller (1992) learns \\nto compute a weight matrix for further processing depending on the input.[14] One of its two \\nnetworks has \"fast weights\" or \"dynamic links\" (1981).[15][16][17] A slow neural network learns by \\ngradient descent to generate keys and values for computing the weight changes of the fast neural'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langgraph\\\\temp.pdf', 'page': 1}, page_content='network which computes answers to queries.[14] This was later shown to be equivalent to the \\nunnormalized linear Transformer.[18][19] \\nAttention with seq2seq \\n[edit] \\nMain article: Seq2seq § History \\nThe idea of encoder-decoder sequence transduction had been developed in the early 2010s (see \\nprevious papers[20][21]). The papers most commonly cited as the originators that produced seq2seq'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langgraph\\\\temp.pdf', 'page': 1}, page_content='are two concurrently published papers from 2014.[20][21] \\nA 380M-parameter model for machine translation uses two long short-term memories (LSTM).[21] Its \\narchitecture consists of two parts. The encoder is an LSTM that takes in a sequence of tokens and'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langgraph\\\\temp.pdf', 'page': 2}, page_content='turns it into a vector. The decoder is another LSTM that converts the vector into a sequence of \\ntokens. Similarly, another 130M-parameter model used gated recurrent units (GRU) instead of \\nLSTM.[20] Later research showed that GRUs are neither better nor worse than LSTMs for \\nseq2seq.[22][23] \\nThese early seq2seq models had no attention mechanism, and the state vector is accessible only'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langgraph\\\\temp.pdf', 'page': 2}, page_content='after the last word of the source text was processed. Although in theory such a vector retains the \\ninformation about the whole original sentence, in practice the information is poorly preserved. This \\nis because the input is processed sequentially by one recurrent network into a fixed-size output \\nvector, which is then processed by another recurrent network into an output. If the input is long,'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langgraph\\\\temp.pdf', 'page': 2}, page_content='then the output vector would not be able to contain all relevant information, degrading the output. \\nAs evidence, reversing the input sentence improved seq2seq translation.[24] \\nThe RNNsearch model introduced an attention mechanism to seq2seq for machine translation to \\nsolve the bottleneck problem (of the fixed-size output vector), allowing the model to process long-'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langgraph\\\\temp.pdf', 'page': 2}, page_content='distance dependencies more easily. The name is because it \"emulates searching through a source \\nsentence during decoding a translation\".[4] \\nThe relative performances were compared between global (that of RNNsearch) and local (sliding \\nwindow) attention model architectures for machine translation, finding that mixed attention had'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langgraph\\\\temp.pdf', 'page': 2}, page_content='higher quality than global attention, while local attention reduced translation time.[25] \\nIn 2016, Google Translate was revamped to Google Neural Machine Translation, which replaced the \\nprevious model based on statistical machine translation. The new model was a seq2seq model where \\nthe encoder and the decoder were both 8 layers of bidirectional LSTM.[26] It took nine months to'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langgraph\\\\temp.pdf', 'page': 2}, page_content='develop, and it outperformed the statistical approach, which took ten years to develop.[27] \\nParallelizing attention \\n[edit] \\nMain article: Attention (machine learning) § History \\nSeq2seq models with attention (including self-attention) still suffered from the same issue with \\nrecurrent networks, which is that they are hard to parallelize, which prevented them to be'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langgraph\\\\temp.pdf', 'page': 2}, page_content='accelerated on GPUs. In 2016, decomposable attention applied a self-attention mechanism \\nto feedforward networks, which are easy to parallelize, and achieved SOTA result in textual \\nentailment with an order of magnitude less parameters than LSTMs.[28] One of its authors, Jakob \\nUszkoreit, suspected that attention without recurrence is sufficient for language translation, thus the'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langgraph\\\\temp.pdf', 'page': 2}, page_content='title \"attention is all you need\".[29] That hypothesis was against conventional wisdom of the time, and \\neven his father, a well-known computational linguist, was skeptical.[29] In the same year, self-attention \\n(called intra-attention or intra-sentence attention) was proposed for LSTMs.[30] \\nIn 2017, the original (100M-sized) encoder-decoder transformer model was proposed in the'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langgraph\\\\temp.pdf', 'page': 2}, page_content='\"Attention is all you need\" paper. At the time, the focus of the research was on \\nimproving seq2seq for machine translation, by removing its recurrence to process all tokens in \\nparallel, but preserving its dot-product attention mechanism to keep its text processing \\nperformance.[1] Its parallelizability was an important factor to its widespread use in large neural \\nnetworks.[31] \\nAI boom era'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langgraph\\\\temp.pdf', 'page': 2}, page_content='networks.[31] \\nAI boom era \\n[edit]'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langgraph\\\\temp.pdf', 'page': 3}, page_content='Already in spring 2017, even before the \"Attention is all you need\" preprint was published, one of the \\nco-authors applied the \"decoder-only\" variation of the architecture to generate fictitious Wikipedia \\narticles.[32] Transformer architecture is now used in many generative models that contribute to the \\nongoing AI boom.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langgraph\\\\temp.pdf', 'page': 3}, page_content='ongoing AI boom. \\nIn language modelling, ELMo (2018) was a bi-directional LSTM that produces contextualized word \\nembeddings, improving upon the line of research from bag of words and word2vec. It was followed \\nby BERT (2018), an encoder-only Transformer model.[33] In 2019 October, Google started using BERT'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langgraph\\\\temp.pdf', 'page': 3}, page_content='to process search queries.[34] In 2020, Google Translate replaced the previous RNN-encoder–RNN-\\ndecoder model by a Transformer-encoder–RNN-decoder model.[35] \\nStarting in 2018, the OpenAI GPT series of decoder-only Transformers became state of the art \\nin natural language generation. In 2022, a chatbot based on GPT-3, ChatGPT, became unexpectedly'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langgraph\\\\temp.pdf', 'page': 3}, page_content='popular,[36] triggering a boom around large language models.[37][38] \\nSince 2020, Transformers have been applied in modalities beyond text, including the vision \\ntransformer,[39] speech recognition,[40] robotics,[41] and multimodal.[42] The vision transformer, in turn, \\nstimulated new developments in convolutional neural networks.[43] Image and video generators'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langgraph\\\\temp.pdf', 'page': 3}, page_content='like DALL-E (2021), Stable Diffusion 3 (2024),[44] and Sora (2024), are based on the Transformer \\narchitecture.')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "db=FAISS.from_documents(documents=documents,embedding=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_db=db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input=\"what is transformer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_3648\\1757252538.py:1: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  vector_db.get_relevant_documents(input)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(id='1e8baac1-525c-4bc1-9703-963142bb31d9', metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langgraph\\\\temp.pdf', 'page': 0}, page_content='\"Transformer\" was picked because Uszkoreit liked the sound of that word.[9] \\nAn early design document was titled \"Transformers: Iterative Self-Attention and Processing for \\nVarious Tasks\", and included an illustration of six characters from the Transformers animated show. \\nThe team was named Team Transformer.[8]'),\n",
       " Document(id='18b4fa77-e186-4132-b71b-0d54258f1779', metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langgraph\\\\temp.pdf', 'page': 0}, page_content='Some early examples that the team tried their Transformer architecture on included English-to-\\nGerman translation, generating Wikipedia articles on \"The Transformer\", and parsing. These \\nconvinced the team that the Transformer is a general purpose language model, and not just good for \\ntranslation.[9] \\nAs of 2024, the paper has been cited more than 100,000 times.[10]'),\n",
       " Document(id='6367a19b-38bf-4446-9830-19c1b0faa2b2', metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langgraph\\\\temp.pdf', 'page': 0}, page_content='the transformer, based on the attention mechanism proposed in 2014 by Bahdanau et al.[4] It is \\nconsidered a foundational[5] paper in modern artificial intelligence, as the transformer approach has \\nbecome the main architecture of large language models like those based on GPT.[6][7] At the time, the'),\n",
       " Document(id='e5c932a6-620e-4a1b-8b67-b224fd6c614a', metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langgraph\\\\temp.pdf', 'page': 0}, page_content='From Wikipedia, the free encyclopedia \\nAn illustration of main components of the \\ntransformer model from the paper \\n\"Attention Is All You Need\"[1] is a 2017 landmark[2][3] research paper in machine learning authored by \\neight scientists working at Google. The paper introduced a new deep learning architecture known as')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_db.get_relevant_documents(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class parser(BaseModel):\n",
    "    topic:str=Field(description=\"selected topic\")\n",
    "    reasoning :str=Field(description=\"reasoning behind the topic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser=PydanticOutputParser(pydantic_object=parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"topic\": {\"description\": \"selected topic\", \"title\": \"Topic\", \"type\": \"string\"}, \"reasoning\": {\"description\": \"reasoning behind the topic\", \"title\": \"Reasoning\", \"type\": \"string\"}}, \"required\": [\"topic\", \"reasoning\"]}\n",
      "``` "
     ]
    }
   ],
   "source": [
    "print(parser.get_format_instructions(),end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages:Annotated[Sequence[BaseMessage],operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_1(state:AgentState):\n",
    "    print(\"==> entering into the agent <===\")\n",
    "    messages=state[\"messages\"]\n",
    "    question=messages[-1]\n",
    "    print(f\" the agent question is {question}\")\n",
    "    template=\"\"\"\n",
    "                your task is to classify the following user query  whether the question is [transformer,not related]\n",
    "                and nothing else you can do\n",
    "                question:{question}\n",
    "                {format_instructions}\n",
    "            \"\"\"\n",
    "    \n",
    "    prompt=PromptTemplate(\n",
    "        input_variables=[question],\n",
    "        template=template,\n",
    "        format_instructions=parser.get_format_instructions()\n",
    "        )\n",
    "    \n",
    "    chain=prompt|llm|StrOutputParser()\n",
    "\n",
    "    response=chain.invoke({\"question\":question,\"format_instructions\":parser.get_format_instructions()})\n",
    "\n",
    "    return {\"messages\":[response]}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_2(state:AgentState):\n",
    "    print(\"==> entering into the llm <==\")\n",
    "    messages=state[\"messages\"]\n",
    "    question=messages[0]\n",
    "    print(f\"the llm question {question}\")\n",
    "    response=llm.invoke(question)\n",
    "    return {\"messages\":[response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_3(state:AgentState):\n",
    "    print(\"==> entering into the rag <==\")\n",
    "    messages=state[\"messages\"]\n",
    "    question=messages[-1]\n",
    "    print(f\"the rag question is {question}\")\n",
    "\n",
    "    template=\"\"\"\n",
    "      Answer the following question based on the user query\n",
    "      {context}\n",
    "      Question:{question}\n",
    "    \"\"\"\n",
    "\n",
    "    prompt=ChatPromptTemplate.from_template(template)\n",
    "\n",
    "    chain=prompt|llm|StrOutputParser()\n",
    "\n",
    "    response=chain.invoke({\"context\":vector_db,\"question\":question})\n",
    "    return {\"messages\":[response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def router(state:AgentState):\n",
    "    print(\"->calling route <-\")\n",
    "\n",
    "    messages=state[\"messages\"]\n",
    "    last_message=messages[-1]\n",
    "    #the question is entering into router:```json\n",
    "    #{\"topic\": \"not Related\", \"reasoning\": \"The query is about a general AI \n",
    "    # concept and not related to Langsmith\"}\n",
    "    print(f\"the question is entering into router:{last_message}\")\n",
    "    if \"not related\" in last_message:\n",
    "        return \"LLM CALL\"\n",
    "    else:\n",
    "        return \"RAG CALL\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#router({\"messages\":[\"what is tansformer\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph=StateGraph(AgentState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x20e89f60f80>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.add_node(\"agent\",function_1)\n",
    "graph.add_edge(START,\"agent\")\n",
    "graph.add_node(\"llm\",function_2)\n",
    "graph.add_node(\"rag\",function_3)\n",
    "\n",
    "graph.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    \n",
    "    router,\n",
    "    {\n",
    "       \n",
    "        \"RAG CALL\":\"rag\",\n",
    "        \"LLM CALL\":\"llm\"\n",
    "    }\n",
    ")\n",
    "\n",
    "graph.add_edge(\"rag\",END)\n",
    "graph.add_edge(\"llm\",END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "app=graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    display(Image(app.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "input=\"what is education\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> entering into the agent <===\n",
      " the agent question is what is education\n",
      "->calling route <-\n",
      "the question is entering into router:```json\n",
      "{\"topic\": \"not related\", \"reasoning\": \"Education is a broad societal concept, not directly related to the capabilities of transformer models.\"}\n",
      "``` \n",
      "\n",
      "==> entering into the llm <==\n",
      "the llm question what is education\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': ['what is education',\n",
       "  '```json\\n{\"topic\": \"not related\", \"reasoning\": \"Education is a broad societal concept, not directly related to the capabilities of transformer models.\"}\\n``` \\n',\n",
       "  AIMessage(content='Education is a multifaceted and complex concept that encompasses much more than just formal schooling. \\n\\nHere are some key aspects of education:\\n\\n**Formal Education:**\\n\\n* **Structured learning:** This typically involves attending schools or universities, following a curriculum, and receiving instruction from qualified teachers. \\n* **Academic subjects:**  Focuses on acquiring knowledge and skills in areas like reading, writing, mathematics, science, history, and the arts.\\n* **Qualifications and credentials:**  Leads to diplomas, degrees, and other certifications that can be valuable for employment and further education.\\n\\n**Informal Education:**\\n\\n* **Lifelong learning:**  Acquiring knowledge and skills outside of formal institutions through experiences, interactions, and self-directed learning.\\n* **Socialization:** Learning about social norms, values, and behaviors through family, friends, communities, and cultural experiences.\\n* **Practical skills:**  Developing hands-on abilities and competencies through apprenticeships, hobbies, and everyday life.\\n\\n**Types of Education:**\\n\\n* **Early Childhood Education:** Focuses on the development of social, emotional, cognitive, and physical skills in young children.\\n* **Primary and Secondary Education:** Provides foundational knowledge and skills for future learning and career paths.\\n* **Higher Education:** Offers specialized knowledge and skills at the college or university level, leading to advanced degrees.\\n* **Vocational Education:**  Prepares individuals for specific trades and occupations.\\n* **Continuing Education:**  Provides opportunities for adults to update their skills, pursue personal interests, or advance their careers.\\n\\n**Purposes of Education:**\\n\\n* **Knowledge and Understanding:** Expanding individuals\\' understanding of the world and their place in it.\\n* **Skill Development:**  Equipping individuals with the tools and abilities to succeed in life, work, and citizenship.\\n* **Personal Growth:**  Fostering intellectual curiosity, critical thinking, creativity, and self-awareness.\\n* **Social Progress:**  Promoting equality, justice, and sustainable development by empowering individuals and communities.\\n\\n**It\\'s important to note that education is constantly evolving and adapting to the changing needs of society. What is considered \"educated\" today may be different from what was valued in the past.**\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 454, 'prompt_tokens': 12, 'total_tokens': 466, 'completion_time': 0.825454545, 'prompt_time': 7.792e-05, 'queue_time': 0.01925792, 'total_time': 0.825532465}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-78be120f-fe90-403b-bd5a-54b651ad07ca-0', usage_metadata={'input_tokens': 12, 'output_tokens': 454, 'total_tokens': 466})]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.invoke({\"messages\":[input]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> entering into the agent <===\n",
      " the agent question is who is president of india\n",
      "->calling route <-\n",
      "the question is entering into router:```json\n",
      "{\"topic\": \"not related\", \"reasoning\": \"This query is about a factual topic (current president of India) and does not relate to transformer models.\"}\n",
      "```\n",
      "==> entering into the llm <==\n",
      "the llm question who is president of india\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': ['who is president of india',\n",
       "  '```json\\n{\"topic\": \"not related\", \"reasoning\": \"This query is about a factual topic (current president of India) and does not relate to transformer models.\"}\\n```',\n",
       "  AIMessage(content='The President of India is **Droupadi Murmu**. \\n\\nShe assumed office on July 25, 2022. \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 33, 'prompt_tokens': 14, 'total_tokens': 47, 'completion_time': 0.06, 'prompt_time': 7.868e-05, 'queue_time': 0.022038179999999997, 'total_time': 0.06007868}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-08207f09-1d0c-4992-8804-5518cdda55b2-0', usage_metadata={'input_tokens': 14, 'output_tokens': 33, 'total_tokens': 47})]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.invoke({\"messages\":[\"who is president of india\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> entering into the agent <===\n",
      " the agent question is what is transformer\n",
      "->calling route <-\n",
      "the question is entering into router:```json\n",
      "{\n",
      "  \"topic\": \"transformer\",\n",
      "  \"reasoning\": \"The user is asking for a definition of 'transformer'.\"\n",
      "}\n",
      "``` \n",
      "\n",
      "==> entering into the rag <==\n",
      "the rag question is ```json\n",
      "{\n",
      "  \"topic\": \"transformer\",\n",
      "  \"reasoning\": \"The user is asking for a definition of 'transformer'.\"\n",
      "}\n",
      "``` \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': ['what is transformer',\n",
       "  '```json\\n{\\n  \"topic\": \"transformer\",\\n  \"reasoning\": \"The user is asking for a definition of \\'transformer\\'.\"\\n}\\n``` \\n',\n",
       "  'While I can\\'t directly access or process information from external systems or specific objects like the `vectorstore` you\\'ve provided, I can certainly give you a definition of \"transformer\":\\n\\n**Transformer**\\n\\nIn the context of artificial intelligence, particularly natural language processing (NLP), a transformer is a type of deep learning model architecture. \\n\\n**Key Features:**\\n\\n* **Attention Mechanism:** Transformers rely heavily on an attention mechanism, which allows the model to focus on different parts of an input sequence when processing information. This enables them to capture long-range dependencies and relationships within text.\\n* **Encoder-Decoder Structure:**  Most transformers have a structure consisting of an encoder and a decoder. The encoder processes the input sequence, while the decoder generates the output sequence.\\n* **Parallel Processing:** Transformers can process information in parallel, making them more efficient than some earlier recurrent neural network (RNN) architectures.\\n\\n**Applications:**\\n\\nTransformers have revolutionized NLP and are used in a wide range of applications, including:\\n\\n* **Machine Translation:**  Translating text from one language to another.\\n* **Text Summarization:** Condensing large amounts of text into shorter summaries.\\n* **Question Answering:**  Providing answers to questions based on a given context.\\n* **Chatbots and Conversational AI:**  Creating chatbots that can engage in natural-sounding conversations.\\n* **Code Generation:**  Generating computer code.\\n\\n**Popular Transformer Models:**\\n\\n* BERT\\n* GPT (Generative Pre-trained Transformer)\\n* T5\\n* RoBERTa\\n* XLNet\\n\\n\\nLet me know if you have any other questions about transformers or NLP!\\n']}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.invoke({\"messages\":[\"what is transformer\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "state={\"messages\":[\"hello how are you\",\n",
    "              \"what is your name\",\n",
    "              \"what's you're hobby\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"what's you're hobby\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state[\"messages\"][-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

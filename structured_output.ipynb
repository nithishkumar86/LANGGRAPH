{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=ChatGroq(model=\"gemma2-9b-it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Gen AI stands for **Generative Artificial Intelligence**.  \\n\\nIt's a type of artificial intelligence that focuses on creating new content, rather than just analyzing existing data. Think of it like this:\\n\\n* **Traditional AI:**  Analyzes data to find patterns and make predictions (e.g., recommending a movie you might like).\\n* **Gen AI:** Uses learned patterns to generate new content (e.g., writing a poem, composing a piece of music, or even creating an image).\\n\\n**Here's a breakdown:**\\n\\n* **How it works:** Gen AI models are trained on massive datasets of text, images, audio, or code. This allows them to learn the underlying patterns and structures within that data. Then, they can use this knowledge to generate new content that resembles the training data.\\n* **Examples:**\\n    * **Text generation:** Chatbots like me, writing assistants, story generators, code completion tools.\\n    * **Image generation:** Creating realistic images from text descriptions (DALL-E 2, Midjourney), enhancing existing images, generating art.\\n    * **Audio generation:** Composing music, creating voiceovers, generating sound effects.\\n    * **Video generation:** Creating short videos, animating characters, generating special effects.\\n\\n**Key things to remember about Gen AI:**\\n\\n* **It's still evolving:** Gen AI models are constantly improving, but they can still make mistakes or generate biased content.\\n* **It's a powerful tool:** Gen AI has the potential to revolutionize many industries, but it's important to use it responsibly.\\n* **It raises ethical questions:**  Issues like copyright, plagiarism, and the potential for misuse need to be carefully considered.\\n\\n\\nLet me know if you have any other questions about Gen AI!\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 372, 'prompt_tokens': 13, 'total_tokens': 385, 'completion_time': 0.676363636, 'prompt_time': 7.785e-05, 'queue_time': 0.023178798, 'total_time': 0.676441486}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-54839f81-4303-4729-b1de-056866d7a741-0', usage_metadata={'input_tokens': 13, 'output_tokens': 372, 'total_tokens': 385})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"what is gen ai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "template=\"\"\"create a joke on given topic {topic} \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=PromptTemplate(input_variables=['topic'],template=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel,Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Product(BaseModel):\n",
    "    joke:str=Field(description=\"given topic\")\n",
    "    rating:int=Field(description=\"give ratings for the joke\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_output=llm.with_structured_output(Product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=prompt|structured_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "response=chain.invoke({\"topic\":\"elephant\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why did the elephant get a job at the library? Because he was good with his trunk!'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.joke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.rating"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#flow through llm->rag-> in langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langgraph.graph import START,StateGraph,END\n",
    "from typing import Annotated\n",
    "from typing import TypedDict\n",
    "from IPython.display import display,Image\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langgraph.prebuilt import ToolNode,tools_condition\n",
    "from langchain.tools import tool\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HF_TOKEN\"]=os.getenv(\"HF_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding=HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=ChatGroq(model=\"gemma2-9b-it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Generative AI, or Gen AI, is a type of artificial intelligence that focuses on creating new content. \\n\\nThink of it like this: instead of just analyzing existing data, Gen AI learns the patterns and structures within that data and uses that knowledge to generate something original. This \"something\" can take many forms:\\n\\n* **Text:** Writing stories, poems, articles, code, dialogue, and more.\\n* **Images:** Creating paintings, photographs, illustrations, and even 3D models.\\n* **Audio:** Generating music, sound effects, and realistic speech.\\n* **Video:** Synthesizing short videos or animations.\\n\\n**Here\\'s how it works in a nutshell:**\\n\\n1. **Training:** Gen AI models are trained on massive datasets of existing content. This allows them to learn the underlying rules and patterns of that content.\\n2. **Generation:** Once trained, the model can use this knowledge to generate new content based on a given prompt or input.\\n\\n**Some popular examples of Gen AI:**\\n\\n* **ChatGPT:** A powerful language model that can engage in natural-sounding conversations and generate different creative text formats.\\n* **DALL-E 2:** An AI system that creates realistic images and art from text descriptions.\\n* **Jukebox:** An AI that can generate music in various styles.\\n\\n**The potential of Gen AI is immense:**\\n\\n* **Creative industries:** Revolutionizing content creation in fields like writing, art, and music.\\n* **Education:** Providing personalized learning experiences and generating educational materials.\\n* **Business:** Automating tasks, improving customer service, and generating marketing content.\\n\\n**However, there are also concerns:**\\n\\n* **Misinformation:** Gen AI can be used to create convincing fake news and propaganda.\\n* **Bias:** Gen AI models can inherit and amplify biases present in the training data.\\n* **Job displacement:** Automation powered by Gen AI may lead to job losses in certain sectors.\\n\\nOverall, Gen AI is a rapidly evolving field with the potential to transform many aspects of our lives. Understanding its capabilities and limitations is crucial for harnessing its benefits while mitigating its risks.\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 443, 'prompt_tokens': 13, 'total_tokens': 456, 'completion_time': 0.805454545, 'prompt_time': 7.457e-05, 'queue_time': 0.019302068000000002, 'total_time': 0.805529115}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-69c6a6f0-5032-4722-bee6-33259d44d5a8-0', usage_metadata={'input_tokens': 13, 'output_tokens': 443, 'total_tokens': 456})"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"what is gen ai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader=PyPDFLoader(file_path=\"C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langgraph\\\\temp.pdf\")\n",
    "docs=loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents=RecursiveCharacterTextSplitter(chunk_size=400,chunk_overlap=40).split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langgraph\\\\temp.pdf', 'page': 0}, page_content='From Wikipedia, the free encyclopedia \\nAn illustration of main components of the \\ntransformer model from the paper \\n\"Attention Is All You Need\"[1] is a 2017 landmark[2][3] research paper in machine learning authored by \\neight scientists working at Google. The paper introduced a new deep learning architecture known as'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langgraph\\\\temp.pdf', 'page': 0}, page_content='the transformer, based on the attention mechanism proposed in 2014 by Bahdanau et al.[4] It is \\nconsidered a foundational[5] paper in modern artificial intelligence, as the transformer approach has \\nbecome the main architecture of large language models like those based on GPT.[6][7] At the time, the'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langgraph\\\\temp.pdf', 'page': 0}, page_content='focus of the research was on improving Seq2seq techniques for machine translation, but the authors \\ngo further in the paper, foreseeing the technique\\'s potential for other tasks like question \\nanswering and what is now known as multimodal Generative AI.[1] \\nThe paper\\'s title is a reference to the song \"All You Need Is Love\" by the Beatles.[8] The name'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langgraph\\\\temp.pdf', 'page': 0}, page_content='\"Transformer\" was picked because Uszkoreit liked the sound of that word.[9] \\nAn early design document was titled \"Transformers: Iterative Self-Attention and Processing for \\nVarious Tasks\", and included an illustration of six characters from the Transformers animated show. \\nThe team was named Team Transformer.[8]'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langgraph\\\\temp.pdf', 'page': 0}, page_content='Some early examples that the team tried their Transformer architecture on included English-to-\\nGerman translation, generating Wikipedia articles on \"The Transformer\", and parsing. These \\nconvinced the team that the Transformer is a general purpose language model, and not just good for \\ntranslation.[9] \\nAs of 2024, the paper has been cited more than 100,000 times.[10]'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langgraph\\\\temp.pdf', 'page': 0}, page_content='For their 100M-parameter Transformer model, they suggested learning rate should be linearly scaled \\nup from 0 to maximal value for the first part of the training (i.e. 2% of the total number of training \\nsteps), and to use dropout, to stabilize training. \\nAuthors \\n[edit] \\nThe authors of the paper are: Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langgraph\\\\temp.pdf', 'page': 0}, page_content='Jones, Aidan Gomez, Lukasz Kaiser, and Illia Polosukhin. All eight authors were \"equal contributors\" \\nto the paper; the listed order was randomized. The Wired article highlights the group\\'s diversity:[8]'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langgraph\\\\temp.pdf', 'page': 1}, page_content='Six of the eight authors were born outside the United States; the other two are children of two \\ngreen-card-carrying Germans who were temporarily in California and a first-generation American \\nwhose family had fled persecution, respectively. \\nBy 2023, all eight authors had left Google and founded their own AI start-ups (except Łukasz Kaiser, \\nwho joined OpenAI).[8][10] \\nHistorical context \\n[edit]'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langgraph\\\\temp.pdf', 'page': 1}, page_content='Historical context \\n[edit] \\nMain articles: Transformer (deep learning architecture) § History, and Seq2seq § History \\nSee also: Timeline of machine learning \\nPredecessors \\n[edit] \\nFor many years, sequence modelling and generation was done by using plain recurrent neural \\nnetworks (RNNs). A well-cited early example was the Elman network (1990). In theory, the'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langgraph\\\\temp.pdf', 'page': 1}, page_content=\"information from one token can propagate arbitrarily far down the sequence, but in practice \\nthe vanishing-gradient problem leaves the model's state at the end of a long sentence without \\nprecise, extractable information about preceding tokens. \\nA key breakthrough was LSTM (1995),[note 1] a RNN which used various innovations to overcome the\"),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langgraph\\\\temp.pdf', 'page': 1}, page_content='vanishing gradient problem, allowing efficient learning of long-sequence modelling. One key \\ninnovation was the use of an attention mechanism which used neurons that multiply the outputs of \\nother neurons, so-called multiplicative units.[11] Neural networks using multiplicative units were later \\ncalled sigma-pi networks[12] or higher-order networks.[13] LSTM became the standard architecture for'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langgraph\\\\temp.pdf', 'page': 1}, page_content='long sequence modelling until the 2017 publication of Transformers. However, LSTM still used \\nsequential processing, like most other RNNs.[note 2] Specifically, RNNs operate one token at a time \\nfrom first to last; they cannot operate in parallel over all tokens in a sequence. \\nModern Transformers overcome this problem, but unlike RNNs, they require computation time that'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langgraph\\\\temp.pdf', 'page': 1}, page_content='is quadratic in the size of the context window. The linearly scaling fast weight controller (1992) learns \\nto compute a weight matrix for further processing depending on the input.[14] One of its two \\nnetworks has \"fast weights\" or \"dynamic links\" (1981).[15][16][17] A slow neural network learns by \\ngradient descent to generate keys and values for computing the weight changes of the fast neural'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langgraph\\\\temp.pdf', 'page': 1}, page_content='network which computes answers to queries.[14] This was later shown to be equivalent to the \\nunnormalized linear Transformer.[18][19] \\nAttention with seq2seq \\n[edit] \\nMain article: Seq2seq § History \\nThe idea of encoder-decoder sequence transduction had been developed in the early 2010s (see \\nprevious papers[20][21]). The papers most commonly cited as the originators that produced seq2seq'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langgraph\\\\temp.pdf', 'page': 1}, page_content='are two concurrently published papers from 2014.[20][21] \\nA 380M-parameter model for machine translation uses two long short-term memories (LSTM).[21] Its \\narchitecture consists of two parts. The encoder is an LSTM that takes in a sequence of tokens and'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langgraph\\\\temp.pdf', 'page': 2}, page_content='turns it into a vector. The decoder is another LSTM that converts the vector into a sequence of \\ntokens. Similarly, another 130M-parameter model used gated recurrent units (GRU) instead of \\nLSTM.[20] Later research showed that GRUs are neither better nor worse than LSTMs for \\nseq2seq.[22][23] \\nThese early seq2seq models had no attention mechanism, and the state vector is accessible only'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langgraph\\\\temp.pdf', 'page': 2}, page_content='after the last word of the source text was processed. Although in theory such a vector retains the \\ninformation about the whole original sentence, in practice the information is poorly preserved. This \\nis because the input is processed sequentially by one recurrent network into a fixed-size output \\nvector, which is then processed by another recurrent network into an output. If the input is long,'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langgraph\\\\temp.pdf', 'page': 2}, page_content='then the output vector would not be able to contain all relevant information, degrading the output. \\nAs evidence, reversing the input sentence improved seq2seq translation.[24] \\nThe RNNsearch model introduced an attention mechanism to seq2seq for machine translation to \\nsolve the bottleneck problem (of the fixed-size output vector), allowing the model to process long-'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langgraph\\\\temp.pdf', 'page': 2}, page_content='distance dependencies more easily. The name is because it \"emulates searching through a source \\nsentence during decoding a translation\".[4] \\nThe relative performances were compared between global (that of RNNsearch) and local (sliding \\nwindow) attention model architectures for machine translation, finding that mixed attention had'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langgraph\\\\temp.pdf', 'page': 2}, page_content='higher quality than global attention, while local attention reduced translation time.[25] \\nIn 2016, Google Translate was revamped to Google Neural Machine Translation, which replaced the \\nprevious model based on statistical machine translation. The new model was a seq2seq model where \\nthe encoder and the decoder were both 8 layers of bidirectional LSTM.[26] It took nine months to'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langgraph\\\\temp.pdf', 'page': 2}, page_content='develop, and it outperformed the statistical approach, which took ten years to develop.[27] \\nParallelizing attention \\n[edit] \\nMain article: Attention (machine learning) § History \\nSeq2seq models with attention (including self-attention) still suffered from the same issue with \\nrecurrent networks, which is that they are hard to parallelize, which prevented them to be'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langgraph\\\\temp.pdf', 'page': 2}, page_content='accelerated on GPUs. In 2016, decomposable attention applied a self-attention mechanism \\nto feedforward networks, which are easy to parallelize, and achieved SOTA result in textual \\nentailment with an order of magnitude less parameters than LSTMs.[28] One of its authors, Jakob \\nUszkoreit, suspected that attention without recurrence is sufficient for language translation, thus the'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langgraph\\\\temp.pdf', 'page': 2}, page_content='title \"attention is all you need\".[29] That hypothesis was against conventional wisdom of the time, and \\neven his father, a well-known computational linguist, was skeptical.[29] In the same year, self-attention \\n(called intra-attention or intra-sentence attention) was proposed for LSTMs.[30] \\nIn 2017, the original (100M-sized) encoder-decoder transformer model was proposed in the'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langgraph\\\\temp.pdf', 'page': 2}, page_content='\"Attention is all you need\" paper. At the time, the focus of the research was on \\nimproving seq2seq for machine translation, by removing its recurrence to process all tokens in \\nparallel, but preserving its dot-product attention mechanism to keep its text processing \\nperformance.[1] Its parallelizability was an important factor to its widespread use in large neural \\nnetworks.[31] \\nAI boom era'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langgraph\\\\temp.pdf', 'page': 2}, page_content='networks.[31] \\nAI boom era \\n[edit]'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langgraph\\\\temp.pdf', 'page': 3}, page_content='Already in spring 2017, even before the \"Attention is all you need\" preprint was published, one of the \\nco-authors applied the \"decoder-only\" variation of the architecture to generate fictitious Wikipedia \\narticles.[32] Transformer architecture is now used in many generative models that contribute to the \\nongoing AI boom.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langgraph\\\\temp.pdf', 'page': 3}, page_content='ongoing AI boom. \\nIn language modelling, ELMo (2018) was a bi-directional LSTM that produces contextualized word \\nembeddings, improving upon the line of research from bag of words and word2vec. It was followed \\nby BERT (2018), an encoder-only Transformer model.[33] In 2019 October, Google started using BERT'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langgraph\\\\temp.pdf', 'page': 3}, page_content='to process search queries.[34] In 2020, Google Translate replaced the previous RNN-encoder–RNN-\\ndecoder model by a Transformer-encoder–RNN-decoder model.[35] \\nStarting in 2018, the OpenAI GPT series of decoder-only Transformers became state of the art \\nin natural language generation. In 2022, a chatbot based on GPT-3, ChatGPT, became unexpectedly'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langgraph\\\\temp.pdf', 'page': 3}, page_content='popular,[36] triggering a boom around large language models.[37][38] \\nSince 2020, Transformers have been applied in modalities beyond text, including the vision \\ntransformer,[39] speech recognition,[40] robotics,[41] and multimodal.[42] The vision transformer, in turn, \\nstimulated new developments in convolutional neural networks.[43] Image and video generators'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langgraph\\\\temp.pdf', 'page': 3}, page_content='like DALL-E (2021), Stable Diffusion 3 (2024),[44] and Sora (2024), are based on the Transformer \\narchitecture.')]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "db=FAISS.from_documents(documents=documents,embedding=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_db=db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "input=\"what is transformer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='afd4a1c3-aa0a-48e3-b69e-661695036770', metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langgraph\\\\temp.pdf', 'page': 0}, page_content='\"Transformer\" was picked because Uszkoreit liked the sound of that word.[9] \\nAn early design document was titled \"Transformers: Iterative Self-Attention and Processing for \\nVarious Tasks\", and included an illustration of six characters from the Transformers animated show. \\nThe team was named Team Transformer.[8]'),\n",
       " Document(id='b26b09a8-d79f-400c-8e99-305b9d4ba038', metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langgraph\\\\temp.pdf', 'page': 0}, page_content='Some early examples that the team tried their Transformer architecture on included English-to-\\nGerman translation, generating Wikipedia articles on \"The Transformer\", and parsing. These \\nconvinced the team that the Transformer is a general purpose language model, and not just good for \\ntranslation.[9] \\nAs of 2024, the paper has been cited more than 100,000 times.[10]'),\n",
       " Document(id='c7abee32-4642-41fa-8173-ad901716bcd5', metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langgraph\\\\temp.pdf', 'page': 0}, page_content='the transformer, based on the attention mechanism proposed in 2014 by Bahdanau et al.[4] It is \\nconsidered a foundational[5] paper in modern artificial intelligence, as the transformer approach has \\nbecome the main architecture of large language models like those based on GPT.[6][7] At the time, the'),\n",
       " Document(id='aa04f642-d67b-47ae-8591-8ad09ca944ec', metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\langgraph\\\\temp.pdf', 'page': 0}, page_content='From Wikipedia, the free encyclopedia \\nAn illustration of main components of the \\ntransformer model from the paper \\n\"Attention Is All You Need\"[1] is a 2017 landmark[2][3] research paper in machine learning authored by \\neight scientists working at Google. The paper introduced a new deep learning architecture known as')]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_db.get_relevant_documents(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages:Annotated[list,add_messages]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_1(state:AgentState):\n",
    "    print(\"==> entering into the llm <==\")\n",
    "    messages=state[\"messages\"]\n",
    "    question=messages\n",
    "    print(f\"the llm question {question}\")\n",
    "    response=llm.invoke(question)\n",
    "    return {\"messages\":[response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_2(state:AgentState):\n",
    "    print(\"==> entering into the rag <==\")\n",
    "    messages=state[\"messages\"]\n",
    "    question=messages[-1]\n",
    "    print(f\"the rag question is {question}\")\n",
    "\n",
    "    template=\"\"\"\n",
    "      Answer the following question based on the user query\n",
    "      {context}\n",
    "      Question:{question}\n",
    "    \"\"\"\n",
    "\n",
    "    prompt=ChatPromptTemplate.from_template(template)\n",
    "\n",
    "    chain=prompt|llm|StrOutputParser()\n",
    "\n",
    "    response=chain.invoke({\"context\":vector_db,\"question\":question})\n",
    "    return {\"messages\":[response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#state={\"messages\":[\"what is gen ai\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function_2(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph=StateGraph(AgentState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x2cdda903fe0>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.add_node(\"llm\",function_1)\n",
    "graph.add_node(\"rag\",function_2)\n",
    "graph.add_edge(\"llm\",\"rag\")\n",
    "graph.set_entry_point(\"llm\")\n",
    "graph.set_finish_point(\"rag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "app=graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    display(Image(app.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> entering into the llm <==\n",
      "the llm question [HumanMessage(content='what is gen ai', additional_kwargs={}, response_metadata={}, id='a8531ffe-0a6c-422d-b245-c3033d751227')]\n",
      "==> entering into the rag <==\n",
      "the rag question iscontent=\"**Generative AI** (Gen AI) is a type of artificial intelligence that focuses on creating new content, rather than simply analyzing or classifying existing data. \\n\\nHere's a breakdown:\\n\\n**What it does:**\\n\\n* **Generates new data:** Gen AI models can produce various forms of content, including:\\n    * **Text:** Articles, stories, poems, dialogue, code\\n    * **Images:** Photos, drawings, artwork\\n    * **Audio:** Music, speech, sound effects\\n    * **Video:** Animations, short films\\n    * **Other:** 3D models, synthetic data\\n\\n* **Learns patterns:** Gen AI models learn these patterns from massive datasets of existing content.\\n\\n* **Creates variations:** Based on the learned patterns, they can generate new content that resembles the training data but is unique.\\n\\n**How it works:**\\n\\n* **Deep learning:** Gen AI primarily relies on deep learning algorithms, particularly neural networks with many layers.\\n* **Training data:** These models are trained on vast amounts of data, allowing them to understand the underlying structures and relationships within the data.\\n* **Probability and prediction:** During generation, the model predicts the most likely next element in a sequence, gradually building up the new content.\\n\\n**Examples:**\\n\\n* **ChatGPT:** Generates human-like text in conversations.\\n* **DALL-E 2:** Creates images from textual descriptions.\\n* **Jukebox:** Generates music in different styles.\\n\\n**Applications:**\\n\\n* **Content creation:** Writing assistance, generating marketing copy, creating art and music.\\n* **Code development:** Automating code generation and debugging.\\n* **Design and prototyping:** Generating 3D models and design concepts.\\n* **Research and development:** Creating synthetic data for training other AI models.\\n\\n**Considerations:**\\n\\n* **Bias:** Gen AI models can inherit biases present in the training data, leading to potentially unfair or discriminatory outputs.\\n\\n* **Misinformation:** The ability to generate realistic content raises concerns about the spread of misinformation and deepfakes.\\n* **Copyright and ownership:** Questions surrounding the ownership and copyright of AI-generated content are still evolving.\\n\\n\\nGen AI is a rapidly advancing field with immense potential to transform various industries and aspects of our lives. However, it's crucial to address the ethical and societal implications associated with its development and deployment.\\n\" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 490, 'prompt_tokens': 13, 'total_tokens': 503, 'completion_time': 0.890909091, 'prompt_time': 0.000110499, 'queue_time': 0.021319749, 'total_time': 0.89101959}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None} id='run-0d74a797-f043-48e1-953c-8a677283a37d-0' usage_metadata={'input_tokens': 13, 'output_tokens': 490, 'total_tokens': 503}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='what is gen ai', additional_kwargs={}, response_metadata={}, id='a8531ffe-0a6c-422d-b245-c3033d751227'),\n",
       "  AIMessage(content=\"**Generative AI** (Gen AI) is a type of artificial intelligence that focuses on creating new content, rather than simply analyzing or classifying existing data. \\n\\nHere's a breakdown:\\n\\n**What it does:**\\n\\n* **Generates new data:** Gen AI models can produce various forms of content, including:\\n    * **Text:** Articles, stories, poems, dialogue, code\\n    * **Images:** Photos, drawings, artwork\\n    * **Audio:** Music, speech, sound effects\\n    * **Video:** Animations, short films\\n    * **Other:** 3D models, synthetic data\\n\\n* **Learns patterns:** Gen AI models learn these patterns from massive datasets of existing content.\\n\\n* **Creates variations:** Based on the learned patterns, they can generate new content that resembles the training data but is unique.\\n\\n**How it works:**\\n\\n* **Deep learning:** Gen AI primarily relies on deep learning algorithms, particularly neural networks with many layers.\\n* **Training data:** These models are trained on vast amounts of data, allowing them to understand the underlying structures and relationships within the data.\\n* **Probability and prediction:** During generation, the model predicts the most likely next element in a sequence, gradually building up the new content.\\n\\n**Examples:**\\n\\n* **ChatGPT:** Generates human-like text in conversations.\\n* **DALL-E 2:** Creates images from textual descriptions.\\n* **Jukebox:** Generates music in different styles.\\n\\n**Applications:**\\n\\n* **Content creation:** Writing assistance, generating marketing copy, creating art and music.\\n* **Code development:** Automating code generation and debugging.\\n* **Design and prototyping:** Generating 3D models and design concepts.\\n* **Research and development:** Creating synthetic data for training other AI models.\\n\\n**Considerations:**\\n\\n* **Bias:** Gen AI models can inherit biases present in the training data, leading to potentially unfair or discriminatory outputs.\\n\\n* **Misinformation:** The ability to generate realistic content raises concerns about the spread of misinformation and deepfakes.\\n* **Copyright and ownership:** Questions surrounding the ownership and copyright of AI-generated content are still evolving.\\n\\n\\nGen AI is a rapidly advancing field with immense potential to transform various industries and aspects of our lives. However, it's crucial to address the ethical and societal implications associated with its development and deployment.\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 490, 'prompt_tokens': 13, 'total_tokens': 503, 'completion_time': 0.890909091, 'prompt_time': 0.000110499, 'queue_time': 0.021319749, 'total_time': 0.89101959}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-0d74a797-f043-48e1-953c-8a677283a37d-0', usage_metadata={'input_tokens': 13, 'output_tokens': 490, 'total_tokens': 503}),\n",
       "  HumanMessage(content='The provided text gives a comprehensive overview of Generative AI (Gen AI). \\n\\nHere are the key takeaways:\\n\\n* **What it does:** Gen AI creates new content (text, images, audio, video, 3D models) by learning patterns from existing data. \\n* **How it works:** Primarily uses deep learning, especially neural networks, trained on massive datasets. It predicts the most likely next element in a sequence to generate new content.\\n* **Examples:** ChatGPT (text), DALL-E 2 (images), Jukebox (music).\\n* **Applications:**  Wide-ranging, including content creation, code development, design, research, and more.\\n* **Considerations:**  Ethical concerns like bias in training data, potential for misinformation, and questions around copyright and ownership need careful consideration.\\n\\n\\nLet me know if you have any specific questions about Gen AI based on this text. \\n', additional_kwargs={}, response_metadata={}, id='ac094550-ab88-4d7b-8144-bebe6788ce45')]}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.invoke({\"messages\":[\"what is gen ai\"]})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
